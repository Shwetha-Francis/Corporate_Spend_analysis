# -*- coding: utf-8 -*-
"""spend analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ukvSztsv3gKaYGENr3aBqX7P7MgO83U9
"""

!pip install gensim
import os, re, gc
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score, mean_squared_error, confusion_matrix
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, IsolationForest
from sklearn.linear_model import LogisticRegression
from sklearn.svm import OneClassSVM
import xgboost as xgb
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
# NLP helpers
from gensim.models import Word2Vec
from sentence_transformers import SentenceTransformer

# Load data
df = pd.read_csv("spend_analysis_dataset.csv")
print("Data shape:", df.shape)
df.head()

# Standardize column names
df.columns = [c.strip() for c in df.columns]

# Convert dates
df['PurchaseDate'] = pd.to_datetime(df['PurchaseDate'], errors='coerce')

# Convert amounts to numeric
for c in ['Quantity','UnitPrice','TotalCost']:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors='coerce')

# Remove duplicates
df = df.drop_duplicates().reset_index(drop=True)

# Fill missing values
# For categorical: fill with 'Unknown', for numeric: fill with median
cat_cols = ['Category','Supplier','Buyer','ItemName']
for c in cat_cols:
    if c in df.columns:
        df[c] = df[c].fillna('Unknown')

num_cols = ['Quantity','UnitPrice','TotalCost']
for c in num_cols:
    if c in df.columns:
        df[c] = df[c].fillna(df[c].median())

# Ensure TotalCost consistent; compute when missing or mismatched
if set(['Quantity','UnitPrice','TotalCost']).issubset(df.columns):
    recomputed = df['Quantity'] * df['UnitPrice']
    # replace TotalCost if NaN
    df.loc[df['TotalCost'].isna(), 'TotalCost'] = recomputed[df['TotalCost'].isna()]
    # create mismatch flag
    df['Cost_mismatch'] = ~np.isclose(df['TotalCost'], recomputed, rtol=1e-3, atol=1e-6)
    print("Cost mismatches:", df['Cost_mismatch'].sum())

# Drop rows with no PurchaseDate after parse
df = df.dropna(subset=['PurchaseDate']).reset_index(drop=True)
print("After cleaning:", df.shape)
df.head()

# Date features
df['Year']   = df['PurchaseDate'].dt.year
df['Month']  = df['PurchaseDate'].dt.month
df['Quarter']= df['PurchaseDate'].dt.quarter
df['Day']    = df['PurchaseDate'].dt.day
df['Weekday']= df['PurchaseDate'].dt.weekday

# Rolling spend (company-level) â€” set index
df = df.sort_values('PurchaseDate').reset_index(drop=True)
company_daily = df.set_index('PurchaseDate').resample('D')['TotalCost'].sum().rename('DailySpend').reset_index()
company_daily['rolling_7d'] = company_daily['DailySpend'].rolling(window=7, min_periods=1).sum()
company_daily['rolling_30d'] = company_daily['DailySpend'].rolling(window=30, min_periods=1).sum()

# Spend per category (aggregate)
spend_by_cat = df.groupby(['Year','Month','Category'])['TotalCost'].sum().reset_index().rename(columns={'TotalCost':'CategorySpend'})

# Per-transaction features
df['SpendPerUnit'] = df['TotalCost'] / df['Quantity'].replace({0:np.nan})
df['SupplierFrequency'] = df['Supplier'].map(df['Supplier'].value_counts())
df['BuyerFrequency'] = df['Buyer'].map(df['Buyer'].value_counts())

# Outlier removal using IQR on TotalCost (flag only)
Q1 = df['TotalCost'].quantile(0.25)
Q3 = df['TotalCost'].quantile(0.75)
IQR = Q3 - Q1
lower = Q1 - 1.5 * IQR
upper = Q3 + 1.5 * IQR
df['Cost_outlier_IQR'] = ((df['TotalCost'] < lower) | (df['TotalCost'] > upper)).astype(int)

# Show summaries
print("Company daily head:\n", company_daily.head())
print("\nSpend by category sample:\n", spend_by_cat.head())
print("\nOutliers flagged:", df['Cost_outlier_IQR'].sum())

# Use ItemName as the description column
def clean_text(s):
    if pd.isna(s): return ""
    s = str(s).lower()
    s = re.sub(r'[^a-z0-9 ]', ' ', s)
    s = re.sub(r'\s+', ' ', s).strip()
    return s

df['ItemName_clean'] = df['ItemName'].apply(clean_text)

# Tokenize and remove stopwords
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
stop = set(stopwords.words('english'))

def tokenize_no_stop(s):
    tokens = s.split()
    return " ".join([t for t in tokens if t not in stop])

df['ItemName_tok'] = df['ItemName_clean'].apply(tokenize_no_stop)

# TF-IDF features sparse; reduce to N features
tfidf = TfidfVectorizer(max_features=300, ngram_range=(1,2))
X_tfidf = tfidf.fit_transform(df['ItemName_tok'])
tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=[f"tfidf_{i}" for i in range(X_tfidf.shape[1])])
df = pd.concat([df.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)
print("TF-IDF shape:", X_tfidf.shape)

# Word2Vec embeddings averaged per ItemName
sentences = [s.split() for s in df['ItemName_tok'].tolist()]
w2v = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=2, epochs=20)
def avg_w2v(tokens):
    vecs = [w2v.wv[t] for t in tokens.split() if t in w2v.wv]
    if len(vecs)==0:
        return np.zeros(w2v.vector_size)
    return np.mean(vecs, axis=0)

w2v_features = np.vstack(df['ItemName_tok'].apply(avg_w2v).values)
w2v_cols = [f"w2v_{i}" for i in range(w2v_features.shape[1])]
w2v_df = pd.DataFrame(w2v_features, columns=w2v_cols)
df = pd.concat([df.reset_index(drop=True), w2v_df.reset_index(drop=True)], axis=1)
print("Word2Vec features added:", w2v_features.shape)

# Prepare dataset for classification
df_class = df.dropna(subset=['Category']).copy()
le = LabelEncoder()
df_class['Category_label'] = le.fit_transform(df_class['Category'])

# Choose features: numeric + tfidf + w2v
numeric_feats = ['Quantity','UnitPrice','TotalCost','SpendPerUnit','SupplierFrequency','BuyerFrequency']
numeric_feats = [c for c in numeric_feats if c in df_class.columns]

tfidf_feats = [c for c in df_class.columns if c.startswith('tfidf_')]
w2v_feats = w2v_cols   # keep as is

# combine
feature_cols = numeric_feats + tfidf_feats + w2v_feats

X = df_class[feature_cols].fillna(0).values
y = df_class['Category_label'].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

scaler_clf = StandardScaler()
X_train = scaler_clf.fit_transform(X_train)
X_test = scaler_clf.transform(X_test)

print("Classification shapes:", X_train.shape, X_test.shape)

# Logistic Regression
log = LogisticRegression(max_iter=1000)
log.fit(X_train, y_train)
pred_log = log.predict(X_test)
print("Logistic Acc:", accuracy_score(y_test, pred_log), "F1 (macro):", f1_score(y_test, pred_log, average='macro'))

# Random Forest
rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)
pred_rf = rf.predict(X_test)
print("RF Acc:", accuracy_score(y_test, pred_rf), "F1 (macro):", f1_score(y_test, pred_rf, average='macro'))

# XGBoost
xgb_clf = xgb.XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)
xgb_clf.fit(X_train, y_train)
pred_xgb = xgb_clf.predict(X_test)
print("XGBoost Acc:", accuracy_score(y_test, pred_xgb), "F1 (macro):", f1_score(y_test, pred_xgb, average='macro'))

# Detailed classification report for best model
best_pred = pred_xgb  # choose whichever performed best
print(classification_report(y_test, best_pred, target_names=le.classes_))

# Save scores to compare later
clf_results = pd.DataFrame({
    'model':['Logistic','RandomForest','XGBoost'],
    'accuracy':[accuracy_score(y_test,pred_log), accuracy_score(y_test,pred_rf), accuracy_score(y_test,pred_xgb)],
    'f1_macro':[f1_score(y_test,pred_log,average='macro'), f1_score(y_test,pred_rf,average='macro'), f1_score(y_test,pred_xgb,average='macro')]
})
clf_results

# Simple feed-forward MLP for tabular + embeddings
num_classes = len(le.classes_)
model = models.Sequential([
    layers.Input(shape=(X_train.shape[1],)),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.4),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(num_classes, activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
es = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
history = model.fit(X_train, y_train, validation_split=0.1, epochs=30, batch_size=128, callbacks=[es], verbose=1)
loss, acc = model.evaluate(X_test, y_test, verbose=0)
print("DL MLP Accuracy:", acc)

# Build category-level time series and forecast
# Choose category to forecast, or loop over categories
cat = df['Category'].unique()[0]
print("Example category:", cat)
ts_cat = df[df['Category']==cat].set_index('PurchaseDate').resample('M')['TotalCost'].sum().rename('MonthlySpend').reset_index()
ts_cat['lag_1'] = ts_cat['MonthlySpend'].shift(1)
ts_cat['lag_2'] = ts_cat['MonthlySpend'].shift(2)
ts_cat['lag_3'] = ts_cat['MonthlySpend'].shift(3)
ts_cat = ts_cat.dropna().reset_index(drop=True)

Xf = ts_cat[['lag_1','lag_2','lag_3']].values
yf = ts_cat['MonthlySpend'].values

# Train/test split (time series)
split_idx = int(len(Xf)*0.8)
X_train_f, X_test_f = Xf[:split_idx], Xf[split_idx:]
y_train_f, y_test_f = yf[:split_idx], yf[split_idx:]

# ML: RandomForestRegressor
rf_fore = RandomForestRegressor(n_estimators=200, random_state=42)
rf_fore.fit(X_train_f, y_train_f)
pred_rf_f = rf_fore.predict(X_test_f)
print("RF Forecast RMSE:", np.sqrt(mean_squared_error(y_test_f, pred_rf_f)))

# DL: simple LSTM
from sklearn.preprocessing import StandardScaler
scaler_fore = StandardScaler()
X_train_sf = scaler_fore.fit_transform(X_train_f)
X_test_sf  = scaler_fore.transform(X_test_f)

X_train_l = X_train_sf.reshape((X_train_sf.shape[0], 1, X_train_sf.shape[1]))
X_test_l  = X_test_sf.reshape((X_test_sf.shape[0], 1, X_test_sf.shape[1]))

lstm = models.Sequential([
    layers.Input(shape=(X_train_l.shape[1], X_train_l.shape[2])),
    layers.LSTM(64, activation='tanh'),
    layers.Dense(32, activation='relu'),
    layers.Dense(1)
])
lstm.compile(optimizer='adam', loss='mse')
lstm.fit(X_train_l, y_train_f, validation_split=0.1, epochs=50, batch_size=8, callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=5)], verbose=0)
pred_lstm = lstm.predict(X_test_l).flatten()
print("LSTM Forecast RMSE:", np.sqrt(mean_squared_error(y_test_f, pred_lstm)))

# IsolationForest (ML)
num_features = ['Quantity','UnitPrice','TotalCost','SpendPerUnit','SupplierFrequency','BuyerFrequency']
num_features = [c for c in num_features if c in df.columns]

X_anom = df[num_features].fillna(0).values
iso = IsolationForest(contamination=0.01, random_state=42)
iso.fit(X_anom)
df['anomaly_iso'] = iso.predict(X_anom)
df['anomaly_iso'] = df['anomaly_iso'].map({1:0, -1:1})
print("IsolationForest anomalies:", df['anomaly_iso'].sum())

# One-Class SVM
ocsvm = OneClassSVM(nu=0.01, kernel='rbf', gamma='scale')
ocsvm.fit(X_anom)
df['anomaly_ocsvm'] = ocsvm.predict(X_anom)
df['anomaly_ocsvm'] = df['anomaly_ocsvm'].map({1:0, -1:1})
print("OneClassSVM anomalies:", df['anomaly_ocsvm'].sum())

# Autoencoder (DL)
inp_dim = X_anom.shape[1]
ae = models.Sequential([
    layers.Input(shape=(inp_dim,)),
    layers.Dense(max(16, inp_dim*2), activation='relu'),
    layers.Dense(8, activation='relu'),
    layers.Dense(max(16, inp_dim*2), activation='relu'),
    layers.Dense(inp_dim)
])
ae.compile(optimizer='adam', loss='mse')
ae.fit(X_anom, X_anom, epochs=50, batch_size=256, validation_split=0.1, callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=5)], verbose=0)
recon = ae.predict(X_anom)
mse = np.mean(np.square(recon - X_anom), axis=1)
threshold = np.percentile(mse, 99)  # top 1% as anomaly
df['anomaly_ae'] = (mse > threshold).astype(int)
print("Autoencoder anomalies (top 1%):", df['anomaly_ae'].sum())

# Classification: use clf_results from earlier and add DL MLP
clf_results.loc[len(clf_results)] = ['DL_MLP', None, None]  # placeholder
clf_results.at[clf_results.index[-1], 'accuracy'] = float(acc)  # from DL MLP
clf_results.at[clf_results.index[-1], 'f1_macro'] = float(f1_score(y_test, model.predict(X_test).argmax(axis=1) ) ) if False else np.nan

# Forecasting RMSEs: use values computed earlier
fore_results = pd.DataFrame({
    'model': ['RandomForest_forecast', 'LSTM_forecast'],
    'rmse': [np.sqrt(mean_squared_error(y_test_f, pred_rf_f)), np.sqrt(mean_squared_error(y_test_f, pred_lstm))]
})
print("Classification results:\n", clf_results)
print("\nForecasting results:\n", fore_results)

# Plots: classification accuracy bar
plt.figure(figsize=(8,4))
sns.barplot(data=clf_results, x='model', y='accuracy')
plt.title('Classification Accuracy Comparison')
plt.show()

# Forecast RMSE comparison
plt.figure(figsize=(6,4))
sns.barplot(data=fore_results, x='model', y='rmse')
plt.title('Forecast RMSE Comparison')
plt.show()

# Anomaly reconstruction error distribution
plt.figure(figsize=(8,4))
sns.histplot(mse, bins=100, kde=True)
plt.axvline(threshold, color='red', linestyle='--', label='anomaly threshold')
plt.title('Autoencoder Reconstruction MSE Distribution')
plt.legend()
plt.show()